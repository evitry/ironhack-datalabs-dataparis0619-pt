{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Python code and commands used in the importing, cleaning, manipulation, and exporting of your data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('GSAF5.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
      "       'Activity', 'Sex ', 'Injury', 'Fatal (Y/N)', 'Species ',\n",
      "       'Investigator or Source', 'pdf', 'href formula', 'href'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_cols = data.isnull().sum()\n",
    "null_cols[null_cols > 0]\n",
    "#Time have 3213 null values -> don't keep it because if this information is often missing, we won't be able to get a trend on the attack hour\n",
    "#Species have 2934 null values -> keep it because we might still want to know what kind of shark attack\n",
    "#Age have 2681 null values -> don't keep it as it is not an interresting information if often missing\n",
    "#I remove Name column as I don't find this information useful\n",
    "\n",
    "drop_cols = ['Time','Age','Name','Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22','Unnamed: 23']\n",
    "data = data.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2016-09-18 00:00:00\n",
      "1       2016-09-18 00:00:00\n",
      "2       2016-09-18 00:00:00\n",
      "3       2016-09-17 00:00:00\n",
      "4       2016-09-15 00:00:00\n",
      "5       2016-09-15 00:00:00\n",
      "6       2016-09-11 00:00:00\n",
      "7       2016-09-07 00:00:00\n",
      "8       2016-09-06 00:00:00\n",
      "9       2016-09-05 00:00:00\n",
      "10      2016-09-05 00:00:00\n",
      "11      2016-09-04 00:00:00\n",
      "12      2016-09-01 00:00:00\n",
      "13      2016-08-29 00:00:00\n",
      "14      2016-08-29 00:00:00\n",
      "15      2016-08-27 00:00:00\n",
      "16      2016-08-25 00:00:00\n",
      "17      2016-08-07 00:00:00\n",
      "18      2016-08-06 00:00:00\n",
      "19      2016-08-04 00:00:00\n",
      "20      2016-07-29 00:00:00\n",
      "21      2016-07-28 00:00:00\n",
      "22      2016-07-28 00:00:00\n",
      "23      2016-07-27 00:00:00\n",
      "24      2016-07-26 00:00:00\n",
      "25      2016-07-24 00:00:00\n",
      "26      2016-07-23 00:00:00\n",
      "27      2016-07-23 00:00:00\n",
      "28      2016-07-20 00:00:00\n",
      "29      2016-07-17 00:00:00\n",
      "               ...         \n",
      "5962           Unknown Date\n",
      "5963           Unknown Date\n",
      "5964           Unknown Date\n",
      "5965           Unknown Date\n",
      "5966           Unknown Date\n",
      "5967           Unknown Date\n",
      "5968           Unknown Date\n",
      "5969           Unknown Date\n",
      "5970           Unknown Date\n",
      "5971           Unknown Date\n",
      "5972           Unknown Date\n",
      "5973           Unknown Date\n",
      "5974           Unknown Date\n",
      "5975           Unknown Date\n",
      "5976           Unknown Date\n",
      "5977           Unknown Date\n",
      "5978           Unknown Date\n",
      "5979           Unknown Date\n",
      "5980           Unknown Date\n",
      "5981           Unknown Date\n",
      "5982           Unknown Date\n",
      "5983           Unknown Date\n",
      "5984           Unknown Date\n",
      "5985           Unknown Date\n",
      "5986           Unknown Date\n",
      "5987           Unknown Date\n",
      "5988           Unknown Date\n",
      "5989           Unknown Date\n",
      "5990           Unknown Date\n",
      "5991           Unknown Date\n",
      "Name: Date, Length: 5992, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Fonctionne mais vaut mieux utliser le bloc d'après\n",
    "lst = []\n",
    "for e in data['Case Number']:\n",
    "    if re.search(\"[0-9]{4}.[0-9]{2}.[0-9]{2}\",e):\n",
    "        splitted_date = re.split(\"\\D\",e)\n",
    "        if splitted_date[1] == \"00\":\n",
    "            splitted_date[1] = \"01\"\n",
    "        if splitted_date[2] == \"00\":\n",
    "            splitted_date[2] = \"01\"\n",
    "        e = datetime(int(splitted_date[0]),int(splitted_date[1]),int(splitted_date[2]))\n",
    "    else:\n",
    "        e = \"Unknown Date\"\n",
    "    lst.append(e)\n",
    " \n",
    "\n",
    "data['Date'] = pd.DataFrame(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       2016-09-18 00:00:00\n",
      "1       2016-09-18 00:00:00\n",
      "2       2016-09-18 00:00:00\n",
      "3       2016-09-17 00:00:00\n",
      "4       2016-09-15 00:00:00\n",
      "5       2016-09-15 00:00:00\n",
      "6       2016-09-11 00:00:00\n",
      "7       2016-09-07 00:00:00\n",
      "8       2016-09-06 00:00:00\n",
      "9       2016-09-05 00:00:00\n",
      "10      2016-09-05 00:00:00\n",
      "11      2016-09-04 00:00:00\n",
      "12      2016-09-01 00:00:00\n",
      "13      2016-08-29 00:00:00\n",
      "14      2016-08-29 00:00:00\n",
      "15      2016-08-27 00:00:00\n",
      "16      2016-08-25 00:00:00\n",
      "17      2016-08-07 00:00:00\n",
      "18      2016-08-06 00:00:00\n",
      "19      2016-08-04 00:00:00\n",
      "20      2016-07-29 00:00:00\n",
      "21      2016-07-28 00:00:00\n",
      "22      2016-07-28 00:00:00\n",
      "23      2016-07-27 00:00:00\n",
      "24      2016-07-26 00:00:00\n",
      "25      2016-07-24 00:00:00\n",
      "26      2016-07-23 00:00:00\n",
      "27      2016-07-23 00:00:00\n",
      "28      2016-07-20 00:00:00\n",
      "29      2016-07-17 00:00:00\n",
      "               ...         \n",
      "5962           Unknown Date\n",
      "5963           Unknown Date\n",
      "5964           Unknown Date\n",
      "5965           Unknown Date\n",
      "5966           Unknown Date\n",
      "5967           Unknown Date\n",
      "5968           Unknown Date\n",
      "5969           Unknown Date\n",
      "5970           Unknown Date\n",
      "5971           Unknown Date\n",
      "5972           Unknown Date\n",
      "5973           Unknown Date\n",
      "5974           Unknown Date\n",
      "5975           Unknown Date\n",
      "5976           Unknown Date\n",
      "5977           Unknown Date\n",
      "5978           Unknown Date\n",
      "5979           Unknown Date\n",
      "5980           Unknown Date\n",
      "5981           Unknown Date\n",
      "5982           Unknown Date\n",
      "5983           Unknown Date\n",
      "5984           Unknown Date\n",
      "5985           Unknown Date\n",
      "5986           Unknown Date\n",
      "5987           Unknown Date\n",
      "5988           Unknown Date\n",
      "5989           Unknown Date\n",
      "5990           Unknown Date\n",
      "5991           Unknown Date\n",
      "Name: Date, Length: 5992, dtype: object\n"
     ]
    }
   ],
   "source": [
    "def clean_Date(e):\n",
    "\n",
    "    if re.search(\"[0-9]{4}.[0-9]{2}.[0-9]{2}\",e):\n",
    "        splitted_date = re.split(\"\\D\",e)\n",
    "        if splitted_date[1] == \"00\":\n",
    "            splitted_date[1] = \"01\"\n",
    "        if splitted_date[2] == \"00\":\n",
    "            splitted_date[2] = \"01\"\n",
    "        cleaned_date = datetime(int(splitted_date[0]),int(splitted_date[1]),int(splitted_date[2]))\n",
    "    else:\n",
    "        cleaned_date = \"Unknown Date\"\n",
    "    \n",
    "    return cleaned_date\n",
    "\n",
    "data['Date'] = data['Case Number'].apply(clean_Date)\n",
    "print(data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I convert Country data into str because some are floats\n",
    "#I remove \"?\", considering the country is correct\n",
    "data['Country'] = data['Country'].astype(str)\n",
    "data['Country'] = data['Country'].str.replace('?', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I search for space at the beginning of country value\n",
    "#I search for space at the end of country value\n",
    "lst = []\n",
    "for e in data['Country']:\n",
    "    #print(e)\n",
    "    if re.search(\"^ \",e):\n",
    "        e = re.sub(\"^ +\",\"\",e)\n",
    "    if re.search(\" $\",e):\n",
    "        e = re.sub(\" +$\",\"\",e)\n",
    "    \n",
    "    lst.append(e)\n",
    "\n",
    "data['Country'] = pd.DataFrame(lst)\n",
    "\n",
    "#var=[y for x in lst for y in x]\n",
    "#data['Country'] = pd.DataFrame(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan, 'Batanes Provine', 'Unknown, treated at Wick, SCOTLAND', 'Salerno', 'Baja California', '300 miles east of Luzon', 'Saint-Denis', 'Roncador Bank', 'Batangas province', '330 to 350 miles east of Wake Island', 'Guyamas', 'Shatt-el-Arab River', 'Eronogo Region', 'Mombasa', 'Madang Province', 'Aichi Prefecture', 'Saint-Paul', 'Valencia', 'Balearics', 'Corfu', 'Tamil Nadu', 'Baie de Sainte-Marie', 'British Colombia', '60 miles north of San Domingo in the West Indies', 'Northern Java', 'Kowloon Peninsula', 'Phuket', 'Florida', 'Territory of Cocos (Keeling) Islands', '800 miles from land', 'Hoogly River', 'Maranhão', 'Vita Levu', 'Cienfuegos Province', 'Alagoas', 'Isla Provedencia', 'Abau Subdistrict,Central Province', 'Saint-Pierre', 'Istria', 'Adana Province', 'Gilbert Islands', 'Near the Andaman & Nicobar Islands', 'Panama Bay (Pacific Ocean)', 'Lamu Archipelago', 'Madang (WO)', 'Grand Terre', 'Magdalena Department', 'Muala', 'Rio San Juan', 'Santo Domingo', 'Makira-Uluwa Province', 'Cabo San Lucas', 'Western Cape Province', 'Suez', 'Clarendon', 'Rayong Province', 'Florida Straits', 'Connecticut', 'South Carolina ', 'Maputo Province', 'Santiago de Cuba Province', 'Saipan', 'Johor', 'Inner Hebrides', 'Sainte-Suzanne', 'Georgia', 'Between Hawaii and U.S.A.', 'Saint-Joseph', 'Kadavu Island Group', 'Louisiade Archipelago', 'Reggio Calabria Province', '10ºS, 142ºE', 'Vera Cruz', 'Berry Islands', 'East Java', 'Makira-Ulawa Province', 'West coast', 'Basrah City', 'Mediterranean Sea', 'Misamis Oriental', 'Tutuila Island', 'East Wall', 'Somewhere between Philadelphia and Hiogo, Japan', 'Imperia Province', 'Andalucia', 'South Devon', 'South Atlantic Ocean', 'Primorje-Gorski Kotar County', 'Argyll', 'San Blas coast', 'Tasmania', 'Taitung ', 'Bimini Islands', 'West End', 'Socotra Islands', 'Off Thessaly', 'Off Ireland', 'Northwest Italy', ' La Libertad', 'Tuamotus', 'Off South American coast', 'Moro Gulf', 'US Virgin Islands', 'Chatham Islands', 'Salinas Bay', 'Line Islands', 'Cay Sal Bank', 'Central Province', 'Between Beira & Maputo', 'Viscayan Sea', 'Ambergris Caye', 'Piraeus', 'Off Samar Island in the Gulf of Leyte', 'Saint Leu', 'Northwest of Viti Levu', 'Johnston Atoll', 'Between New Ireland & New Britain', 'Upolu Island', 'New Mexico', 'Rigo subdistrict', 'Lomaiviti  Island Group', '25 km off the coast of Iran & 483km from mouth of Persian Gulf', 'Porto Seguro', 'Wakayama Prefecture', 'New Georgia', 'Mexico / Caribbean Sea', '180 miles southeast of Okinawa', 'St. Catherine', 'St. Anne', 'Dorset', 'Wallis and Futuna', 'Muhafazat Hadramawt', 'Bali', 'Manila', 'Gulf Province', 'Caribbean Sea', 'Apolima Strait', 'Central Tuamotu', 'Out Islands', 'Antarctic Ocean', 'Central Philippines', 'San Blas', 'Antsiranana Province', 'Sinaloa', 'Nice & Marseilles', 'Laucala Island', 'South shore ', 'North & South Carolina', 'Baatan', 'Off the western coast of peninsular Malaysia', 'Cargados Carajos Shoals (St. Brandon)', 'Inhambe Province', 'Manus Island', 'Málaga ', 'Western Caroline Islands', 'Green Bay', 'South Chungcheong Province', 'Kumamoto Prefecture', 'Cornwall', 'Andaman Islands', '2 to 3 miles off Taboguilla Island, Pacific Ocean', 'Pennsylvania', 'North Carolina', '300 miles from Antigua', 'Rio Grande de Norte', 'Moray', 'Minerva Reef', 'Khuzestan Province', 'Kochi Prefecture', 'Saint-Louis', 'South Sinai, Gulf of Aqaba', 'Rangoon', 'Sinai Peninsula', 'Corregidor Island', 'Canary Islands', 'Aden', 'Alinglaplap Atoll', 'Luzon Island', 'Tamaulipas', 'Norfolk Island', 'San Blas Islands', 'Alabama', \"L'Etang-Sale\", 'Malaga', 'Black River', 'Grand Baie', 'Teramo', 'Genoa Province', 'La Libertad', 'Sainte-Marie', 'Eastern  Province', 'Between Hawaii & Wake Island', \"35º39 : 165º8'\", 'Estuaire Province', 'Caicos Bank', 'Western Papuan Gulf', '22ºN, 88ºE', 'Niua ', '30 nm from Singapore', 'Vanua Levu', 'St. Georges ', 'Liguria', 'Northern Bahamas', 'Izo Islands', 'Guam', 'Cikobia Island (north of Vanua Levu)', ' North Carolina', 'Sandaun Province', 'Oaxaca', \"L' Etang Salé-les-Bains\", 'Santiago Island', 'Guerrero', 'Between Somalia & Yemen', 'Okayama Prefecture', 'Caribbean Coast', '1000 miles west of Hawaii', 'Catalunya', 'Havana Province', 'Istanbul', 'Sants-Montjic', 'South Island, near Karitane north of Dunedin', 'Ratak ', 'Moluccas', 'Mount Lebanon', 'Guantanamo Province', 'In the English Channel ', 'Santa Isabel Province', 'Georges Bank', 'Cook Islands', '5aint-Denis', 'Palmyra Atoll', 'Jeju Province', 'Tuamotos', 'Samaná Province', 'Peter the Great Bay, Khasan, Primorsky Krai (Far East)', 'Bay of Campeche', \"Vava'u\", 'Mersin Province', '\"Head of the Gulf\"', 'Nicoya Peninsula', 'Gran Canaria', 'Kentucky', 'Mugla Province', 'South Coast, East New Britain', 'Rio de Janeiro', 'Kuril Islands in the Pacific', 'Holquin Province', 'Bay of Maputu', 'Mississippi', 'Illeginni Atoll', 'Munxar Reef', 'Enroute from Suez to Aden (Yemen)', 'Congreve Channel', 'Skagerrak arm of the North Sea', '(Southwestern Pacific)', 'Northern Peloponnese', 'Florida ', 'Eastern Catalona', 'Trieste', 'Venice Province', 'Canal Zone', 'Matanzas Province (north coast)', 'Curacao', 'Nueva Esparta', 'Antalya Province', 'Bayelsa State', 'Guanacaste', 'Great Exuma Island', 'Western District', 'Marovo Lagoon', 'Saint-Philippe', 'Viti Levu', 'Puntarenas Province', 'Cap-Vert Peninsula', 'Massachusetts', 'San Andrés archipelago', 'Bois-Blanc ', 'Pacific coast', \"Ha'api \", 'Inner Islands', 'Milne Bay Province', 'Los Roques  Islands', 'Dodecanese Islands', 'Devon', 'Bougainville (North Solomons)', 'Miyako', 'Hokkaido Prefecture', 'Tiburon Peninsula', 'Alicante Province', 'Cortés', 'Northern District', 'West Bengal', 'Isle of Wight', 'Demerara County', 'South Korea', 'Tafea Province', 'Southland', 'Bay of Fundy', 'Limpopo River', 'Southwest coast', 'Zadar County', 'Bandar Ma\\x92shur sea inlet', 'Providenciales', 'Gulf of Lyons', 'Western Viscayas', 'New Brunswick', '18S / 50E', 'Liguaria', 'Quintana Roo', 'Maluku Province', 'Ionian Sea', 'Yucatan Channel', \"Nuku'alofa\", 'Guerro', 'Conservatória District', 'Bwagaoia', 'Lomaiviti Provine', 'Cyclades', 'Transvaal', 'Oslo Fjord', '300 miles east of St. Thomas (Virgin Islands)', 'Galapagos Islands', 'Edinburgh', 'Sardinia', 'Clearwater Bay', 'Santa Cruz Island', 'Ancona Province', 'Elqui Province', 'Rocha ', 'Dar-es-Salaam ', 'Rodrigues', 'Trelawney Province', 'Moorea', 'South Province', 'Queaon', ' Manila Bay', 'Biserta', 'Santa Elena', 'Cyclades archipelago', 'Casamance', 'Delagoa Bay', 'Strait of Malacca', 'Bernardino Strait near Gulf of Leyte', 'Southern Thailand', 'Off the Coromandel Peninsula, North Island', 'San Carlos', 'North Province', 'Near Bougainville (North Solomons)', 'Simpson Bay', 'Ganges-Brahmaputra delta', 'Namonuito Atoll', 'New Jersey', 'New Ireland Province, Bismarck Archipelago', 'Attica', 'Fujairah Emirate', 'Guadalcanal Province', 'Western Banks', 'Khánh Hòa Province', 'Saint-Paul ', 'Wake Island', 'Texas', 'Saint-Benoit', '33N, 68W', 'Corfu Island', 'North of Pernambuco, Brazil', 'Kadavu', 'Kerala', 'Ligurian Sea', 'Western Caroline Islands (North Pacific Ocean)', 'Island of Volos', 'Victoria ', 'New Ireland, Bismarck Archipelago', 'Magarita or Cubagua Islands', 'Viti Levu Island', 'Alaska', ' Lau Province', 'Kwajalein', 'Panama City', 'Viti Levu group', 'Andros Islands', 'Cádiz', 'Admiralty Islands, Manus Province', 'Near the Fiji Islands', 'Quezon', 'Ascension Bay', 'Shefa Province', 'Pagasitikos Gulf', 'Cheshire', 'Inhambane Province', 'Northlands', 'California', \"Grand'Anse\", 'Banaadir Region', 'Between Noumea & Sydney', 'United Arab Emirates', 'Caroline Islands', 'Okinawa Prefecture', 'Morobe Province', 'Gujarat', 'Villa Clara Province', 'Between Southampton & Canary Islands', 'Merizo', 'Taranto', 'Wakaya Island', 'Cyrenaica', 'Calvados Archipelago', 'South Australia', 'Antibes', 'La Saline-les-Bains', 'Northern Taiwan', 'New York', 'Conakry Region', '9.35N 79.35W', 'Wake Island (EnenKio)', ' Kikori River mouth', \"St John's\", 'Cat Cay', \"St. Mary's Parish\", 'Bora Bora', 'Valencia ', 'Karun River', 'Herzliyah', \"South Ch'ungch'ong Province\", 'Grand Canary Island', 'Kagoshima Prefecture', 'South China Sea 200 miles from Hong Kong', 'Colon Province', 'Syracuse', ' Split-Dalmatia Count,', 'Mercury Islands', 'Catalonia', 'Alicante', 'South of the Equator ', 'Tel Aviv', 'Praslin', ' New Jersey', 'Slovenia', 'New Territories', 'Riau Province', 'Moala Island', 'Bikini Atoll', 'Miyako Island', 'Vancouver', 'Costa Blanca', 'Dubai', 'Boa Vista Island', 'Off Libya', 'Atsumi peninsula', 'Isle of Man', 'Bay Islands', 'Palawan', 'Rangiroa', 'Southern Cyprus', 'Illinois', 'East Flores', 'Rombion Province', 'Surigao del Norte', 'North Devon', 'Queensland', 'Hong Kong', 'Western Area', 'Genoa  Province', 'Corfu ', 'Umm al Qaywayan Province', 'Duke of York Islands', 'Island of Kos', 'Grand Turk Island', 'Near Puntarenas', 'Chungnam', 'Montserrado', 'Shanghai', \"250 miles southwest of O'ahu, Hawaii\", 'Anatolia', 'Colima', '19S, 178?E', 'East New Britain', 'Telyakovsky Bay, Khasan,  Primorsky Krai (Far East)', 'Bocas del Toro Province', 'Western Australia', 'Off the coast of West Africa', '12 miles off the north coast', 'Tyrrhenian Sea', 'Torres Strait', 'KwaZulu-Natal', 'West Africa', 'Carpathian Sea', 'Pinas Bay', 'Orissa', 'Torres Strait ', 'Sfax', 'Madang', 'Ysabel Island', 'North Carolina ', 'Vitu Levu', 'Easter Ross', 'New South Wales', 'Lagos ', 'Veracruz ', 'Bay of Biscay', 'Abaco Islands', 'Northern Province', 'Coquimbo', 'Argyllshire', 'On the Kowloon penisula, south of Sai Kung', 'Woodlark Islands', 'New Ireland Province', 'Marches region', 'Eastern Caroline Islands', 'Halifax', 'Eastern Province', ' Primorje-Gorski Kotar County', 'Virginia', 'North Palawan', 'Maharashtra', 'In the Gulf Stream ', 'Gulf of Panama', 'Port Louis Province', 'Brittany', 'Between Honiara & Isabel Island', 'Pernambuco', 'Kwajalein Atoll', 'Between Hastings & Fairlight, Sussex', \"L'Etang-Salé\", 'Tongapatu Group', 'Saint-Gilles-les-Bains', 'Taranto province', 'Sharon', 'Between Comores & Madagascar', '600 nm west of the Canary Islands', 'Newfoundland', 'Abau Sub District, Central Province', 'Bay of Bengal', 'Leyte Island', 'Bay of Maputo', 'Between Perth & Colombo', 'Malaita Province', 'St. Andrew Parish', '1,000 miles east of Hawaii', 'Bocas del Toro', 'Sussex', 'South Island', 'Guerrrero', 'Buenos Aires Province', 'Northwest of Papua New Guinea', 'Sicily', 'Loyalty Islands', 'New Providence Island', 'In transit between Tinian and Leyte', 'Ryukyu', 'Mindanao', '150 miles offshore', 'Trois-Bassins', 'Jakarta Harbour', '40 miles south of Naples ', 'Ralik Archipelago', 'New Britain, Bismarck Archipelago', 'Naples Province', \"Ha'api\", 'North China', 'Grand Bahama Island', 'North Island', 'Cap Vert Peninsula', 'Eastern Cape  Province', 'Pearl Islands', 'Aulong Island', 'Gibraltar', 'Yasawa Islands', 'Turtle Bogue', 'Zamboanga del Sur Province', 'Lake Nicaragua (fresh water)', 'Lower San Juan River', 'Bahia', 'Saint Gilles ', 'Luzon', 'Ralik Chain', 'Rio Grande Do Sul', 'Mozambique Channel', 'Near Dakar, Cap Vert Peninsula', 'Paraiba', 'Singapore Harbor', 'Missouri', 'Eleuthera', 'Sucre', 'Calabria', 'Southern District', 'PANAMA', 'Queensland ', 'Northern (Oro) Province', 'KwaZulu-Natal between Port Edward and Port St Johns', 'Chatham Islands, east of New  Zealand', 'Las Perlas archipelago', 'English Channel', 'Shatt-al-Arab River', 'Istria County', 'St. Johns Reef', 'Primorje-Gorski Kotar County ', 'Negros ', 'Tyrrenian Sea', 'Nagasaki Prefecture', 'Ho Ha Wan Marine Park', '165  miles from Bermuda', 'Granada', 'New York ', 'Provence', 'Mangaia Island', 'Red Sea', 'Oregon', '200 nm southeast of Manila', 'Northern Territory', 'Delta', 'Between Kwajalein Atoll & Johnston Island', 'Vava\\x92u', 'Foveaux Strait', 'Off coast of West Africa', 'Eastern Cape Province', 'East Sepik', 'Arran', 'Fernando Po Island', 'Ahirkapi coast', 'Louisiana', 'South Island?', 'Island of St. Thomas', 'North Region', 'Puerto Rico', 'St Michael Parish', 'Limón Province', 'Camaguey Province', 'Rocha', 'Cook islans', 'Le Port', 'Los Vilos', 'Golfo de Venezia', '740 miles SE of Tarawa Atoll', 'Galica', 'Carabobo', 'Basrah', 'Saint-Benoît', 'In Convoy OB 274', 'Honiara', 'Walkers Cay', 'Hawaii', 'Makora-Ulawa Province', 'Victoria', 'Java', 'Cape Haitien', 'Mafia Island', 'Andikira Fokithes', 'South Sinai Peninsula', 'Gaza', 'Lucy', 'Fife', 'Sago Prefecture', 'Milne Bay  Province', 'Paget', 'Trinidad', 'Mindoro Occidental', 'Masbate', 'Kingston Parish', 'Zambesi River', \"Côte d'Azur \", 'North Pacific coast', 'Western Area ', 'Toamasina Province', 'Delaware', 'Taveuni', 'French Southern Territories', 'Rhode Island', 'Open sea', 'Southern Province', 'Barlavento Islands', 'Phoenix Islands', 'Bay of Monaco', 'Sea of Japan', 'Society Islands', 'Tuscany', 'East Yorkshire', 'East of the Gulf of Aqaba', ' Loyalty Islands', 'Kagawa Prefecture', 'Manfredonia ', 'Saint-Leu', 'Gulf of Tadjoura', 'Brindisi Province', 'Tokyo Prefecture', 'Phang nga Province', 'Bardestrand', 'Tabuk Province', 'Rivers State', 'Colón Province', 'Norfolk', 'Washington', 'Middle Caicos', 'Lomaiviti Province', 'Tavenui', 'Between Timor & Darwin, Australia', 'Pacific Ocean', 'Kent', 'Galicia', 'Strait of Messina', 'Worcestershire', 'Saint-Gilles', 'Between DR and Puerto Rico', 'Cape Coast', 'Between England & South Africa', '04.05N-13.23W', 'Off Vanua Levu', 'Mirs Bay ', 'Southern Japan', 'Beaufonds', 'New Britain', 'Salerno Province', 'Midway Atoll', 'Off coast of Ecuador', 'Altagracia Province', 'Mindoro', 'Sanma Province', 'St. Thomas Bay', 'West New Britain Province', 'Hamilton', 'Chatham Islands ', 'Nova Scotia', 'Eniwetok Atoll', 'Shat-Al-Arab River', 'Grand Cayman', 'Ehime Prefecture', 'Isles del Rosario', 'Golfo di Genova in the Ligurian Sea', 'Westmoreland Parish', 'Alpes Maritime', 'Ibaraki Prefecture', 'Off Cape Haitien', 'Off the coast of South America', 'New Ireland', 'Antofagasta Province', 'Maryland', 'Kedah', 'East New Britain Province', 'Colon', 'Tongatapu', 'Exuma Islands', 'Western Province', \"Côte d'Azur  \", 'Amirante Islands', 'Camiguin Island', 'Red Sea State', 'Gulf of Suez', 'South Carolina', 'Taipei Hsien', 'Coast Province', 'Western Luzon Island', 'Adriatic Sea', 'Madeira Islands', 'South Pacific Ocean', 'Maine', 'Leyte', 'Cook Strait', 'Malampa Province', 'Tamilnadu', 'Bocas', 'Santa Catarina State', 'Binh Dinh Province', 'North Sumatra', 'Cavite Province, Luzon', 'East coast', 'Harare Province', 'Valpariso Province', 'Anzoategui', 'Thessaly', 'Lomaloma, Lau', ' Split-Dalmatia County', 'Bird Island', 'Bonin Islands', 'Primorsky Krai', 'Off Green Island', 'Lukovo', 'Lau Group', 'Ba Ria-Vung Tau  Province', '400 miles southeast of Sri Lanka', 'Between Australia & USA', 'Savona', 'd\\x92Étang-Salé', 'West of Ceylon (Sri  Lanka)', 'Port Shelter', 'Madeira', 'Veracruz', 'Romblon Province'}\n"
     ]
    }
   ],
   "source": [
    "print(set(data['Area']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Area'] = data['Area'].str.replace('\\\"','')\n",
    "data['Area'] = data['Area'].str.replace(\"Tavenui\",\"Taveuni\")\n",
    "data['Area'] = data['Area'].str.replace(\"Tamilnadu\",\"Tamil Nadu\")\n",
    "data['Area'] = data['Area'].str.replace(\"Guerro\",\"Guerrero\")\n",
    "data['Area'] = data['Area'].str.replace(\"Guerrrero\",\"Guerrero\")\n",
    "data['Area'] = data['Area'].str.replace(\"islans\",\"Islands\")\n",
    "data['Area'] = data['Area'].str.replace(\"Province\",\"\")\n",
    "data['Area'] = data['Area'].str.replace(\"Region\",\"\")\n",
    "data['Area'] = data['Area'].str.replace(\"shire\",\"\")\n",
    "data['Area'] = data['Area'].str.replace(\"^$\",\"Not specified\")\n",
    "data['Area'] = data['Area'].str.replace(\"^ +\",\"\")\n",
    "data['Area'] = data['Area'].str.replace(\" +$\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Location'] = data['Location'].str.replace(\"\\(\",\"\")\n",
    "data['Location'] = data['Location'].str.replace(\"\\)\",\"\")\n",
    "data['Location'] = data['Location'].str.replace(\"^$\",\"Not specified\")\n",
    "data['Location'] = data['Location'].str.replace(\"^ +\",\"\")\n",
    "data['Location'] = data['Location'].str.replace(\" +$\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Case Number', 'Date', 'Year', 'Type', 'Country', 'Area', 'Location',\n",
      "       'Activity', 'Name', 'Sex', 'Age', 'Injury', 'Fatal (Y/N)', 'Time',\n",
      "       'Species ', 'Investigator or Source', 'pdf', 'href formula', 'href',\n",
      "       'Case Number.1', 'Case Number.2', 'original order', 'Unnamed: 22',\n",
      "       'Unnamed: 23'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#rename Sex column without space\n",
    "data.rename(columns={\"Sex \":\"Sex\"}, inplace=True)\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan, 'lli', 'M ', 'F', 'N', '.', 'M'}\n"
     ]
    }
   ],
   "source": [
    "print(set(data['Sex']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-492605ca2c9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"lli\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Not specified\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"^$\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Not specified\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Not specified\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"^ +\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: ufunc 'isnan' not supported for the input types, and the inputs could not be safely coerced to any supported types according to the casting rule ''safe''"
     ]
    }
   ],
   "source": [
    "data['Sex'] = data['Sex'].str.replace(\"N\",\"Not specified\")\n",
    "data['Sex'] = data['Sex'].str.replace(\"\\.\",\"Not specified\")\n",
    "data['Sex'] = data['Sex'].str.replace(\"lli\",\"Not specified\")\n",
    "data['Sex'] = data['Sex'].str.replace(\"^$\",\"Not specified\")\n",
    "data['Sex'] = data['Sex'].str.replace(\"^ +\",\"\")\n",
    "data['Sex'] = data['Sex'].str.replace(\" +$\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{nan, 'M', 'Not specified', 'F'}\n"
     ]
    }
   ],
   "source": [
    "print(set(data['Sex']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Fatal (Y/N)'] = data['Fatal (Y/N)'].astype(str)\n",
    "data['Fatal (Y/N)'] = data['Fatal (Y/N)'].str.replace(\"^ +\",\"\")\n",
    "data['Fatal (Y/N)'] = data['Fatal (Y/N)'].str.replace(\" +$\",\"\")\n",
    "\n",
    "lst = []\n",
    "for e in data['Fatal (Y/N)']:\n",
    "    #print(e)\n",
    "    if e != \"N\" or e != \"Y\":\n",
    "        e = \"Not specified\"\n",
    "    \n",
    "    lst.append(e)\n",
    "\n",
    "data['Fatal (Y/N)'] = pd.DataFrame(lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sauvegarde\n",
    "lst = []\n",
    "for e in data['Country']:\n",
    "    #print(e)\n",
    "    if re.search(\"^ \",e):\n",
    "        lst.append(re.sub(\"^ +\",\"\",e))\n",
    "    if re.search(\" $\",e):\n",
    "        lst.append(re.sub(\" +$\",\"\",e))\n",
    "    \n",
    "    \"\"\"else:\n",
    "        lst.append(e)\"\"\"\n",
    "        \n",
    "#var=[y for x in lst for y in x]\n",
    "#data['Country'] = pd.DataFrame(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I search for date with format JJ-MMM-YY or JJ-MMM-YYYY and I add it to my list\n",
    "#For short date, I search only the year\n",
    "#I will need to search for other date format\n",
    "lst = []\n",
    "for e in data['Date']:\n",
    "    if len(e)>5:\n",
    "        lst.append(re.findall(\"[0-9]{2}-[A-Za-z]{3}-[0-9]*\",e))\n",
    "    else:\n",
    "        lst.append(re.findall(\"[0-9]{4}\",e))\n",
    "    \n",
    "#len(lst)\n",
    "#data.shape[0]\n",
    "var=[y for x in lst for y in x]\n",
    "data['Date'] = pd.DataFrame(var)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "for e in data['Date']:\n",
    "    #print(e)\n",
    "    if re.search(\"[0-9]{1,2}.[A-Za-z]+.[0-9]+\",e):\n",
    "        e = re.findall(\"[0-9]{1,2}.[A-Za-z]+.[0-9]+\",e)\n",
    "    elif re.search(\"[A-Za-z]+.[0-9]+\",e):\n",
    "        e = re.findall(\"[A-Za-z]+.[0-9]+\",e)\n",
    "    elif re.search(\"[0-9]{4}\",e):\n",
    "        e = re.findall(\"[0-9]{4}\",e)\n",
    "        \n",
    "    lst.append(e)\n",
    "\n",
    "data['Date'] = pd.DataFrame(lst)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      USA\n",
       "1                      USA\n",
       "2                      USA\n",
       "3                AUSTRALIA\n",
       "4                AUSTRALIA\n",
       "5                AUSTRALIA\n",
       "6                      USA\n",
       "7                      USA\n",
       "8            NEW CALEDONIA\n",
       "9                      USA\n",
       "10               AUSTRALIA\n",
       "11                     USA\n",
       "12                     USA\n",
       "13                     USA\n",
       "14                     USA\n",
       "15                 REUNION\n",
       "16                     USA\n",
       "17                 BAHAMAS\n",
       "18                     USA\n",
       "19                     USA\n",
       "20                   SPAIN\n",
       "21                   CHINA\n",
       "22               AUSTRALIA\n",
       "23                     USA\n",
       "24               AUSTRALIA\n",
       "25                   JAPAN\n",
       "26               AUSTRALIA\n",
       "27                 BAHAMAS\n",
       "28               AUSTRALIA\n",
       "29                     USA\n",
       "               ...        \n",
       "5962      PAPUA NEW GUINEA\n",
       "5963                 BURMA\n",
       "5964                 ITALY\n",
       "5965                GREECE\n",
       "5966                BELIZE\n",
       "5967             AUSTRALIA\n",
       "5968               REUNION\n",
       "5969          SOUTH AFRICA\n",
       "5970             AUSTRALIA\n",
       "5971          SOUTH AFRICA\n",
       "5972             AUSTRALIA\n",
       "5973                   USA\n",
       "5974               VIETNAM\n",
       "5975          SOUTH AFRICA\n",
       "5976          SOUTH AFRICA\n",
       "5977                  FIJI\n",
       "5978                   USA\n",
       "5979          SOUTH AFRICA\n",
       "5980          SOUTH AFRICA\n",
       "5981                  ASIA\n",
       "5982                   USA\n",
       "5983             AUSTRALIA\n",
       "5984             AUSTRALIA\n",
       "5985             AUSTRALIA\n",
       "5986             AUSTRALIA\n",
       "5987             AUSTRALIA\n",
       "5988             AUSTRALIA\n",
       "5989                   USA\n",
       "5990                PANAMA\n",
       "5991    CEYLON (SRI LANKA)\n",
       "Name: Country, Length: 5992, dtype: object"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Case Number               object\n",
       "Date                      object\n",
       "Year                       int64\n",
       "Type                      object\n",
       "Country                   object\n",
       "Area                      object\n",
       "Location                  object\n",
       "Activity                  object\n",
       "Name                      object\n",
       "Sex                       object\n",
       "Age                       object\n",
       "Injury                    object\n",
       "Fatal (Y/N)               object\n",
       "Time                      object\n",
       "Species                   object\n",
       "Investigator or Source    object\n",
       "pdf                       object\n",
       "href formula              object\n",
       "href                      object\n",
       "Case Number.1             object\n",
       "Case Number.2             object\n",
       "original order             int64\n",
       "Unnamed: 22               object\n",
       "Unnamed: 23               object\n",
       "dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "data type 'datetime' not understood",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mpandas_dtype\u001b[1;34m(dtype)\u001b[0m\n\u001b[0;32m   2010\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2011\u001b[1;33m         \u001b[0mnpdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2012\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data type \"datetime\" not understood",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-09066233a100>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Clean Date column\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'datetime'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#print(set(data['Date']))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#data['Date'] = data['Date'].str.replace('Reported ', '')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   5689\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5690\u001b[0m             new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[1;32m-> 5691\u001b[1;33m                                          **kwargs)\n\u001b[0m\u001b[0;32m   5692\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'astype'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m    393\u001b[0m                                             copy=align_copy)\n\u001b[0;32m    394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 395\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    396\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[1;32m--> 534\u001b[1;33m                             **kwargs)\n\u001b[0m\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    593\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[1;31m# convert dtypes if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         \u001b[0mdtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpandas_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    596\u001b[0m         \u001b[1;31m# astype processing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_dtype_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mpandas_dtype\u001b[1;34m(dtype)\u001b[0m\n\u001b[0;32m   2015\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data type not understood\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2016\u001b[0m         raise TypeError(\"data type '{}' not understood\".format(\n\u001b[1;32m-> 2017\u001b[1;33m             dtype))\n\u001b[0m\u001b[0;32m   2018\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2019\u001b[0m     \u001b[1;31m# Any invalid dtype (such as pd.Timestamp) should raise an error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: data type 'datetime' not understood"
     ]
    }
   ],
   "source": [
    "#Clean Date column\n",
    "#print(set(data['Date']))\n",
    "#data['Date'] = data['Date'].str.replace('Reported ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
